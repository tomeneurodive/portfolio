{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7a1f6ff-962a-413c-b041-2b104716b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import shap\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from statistics import mean\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt import space_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_palette(\"coolwarm_r\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452133f4-1b12-4e11-ae73-16f8dccadc40",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01bfe3ab-f0d8-4720-ac20-fc67f6e82b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data files\n",
    "\n",
    "train = pd.read_csv(r\"C:\\Users\\NDO00\\OneDrive\\デスクトップ\\MI\\mi_book\\e-commerce\\train.csv\",index_col = 'id')\n",
    "test = pd.read_csv(r\"C:\\Users\\NDO00\\OneDrive\\デスクトップ\\MI\\mi_book\\e-commerce\\test.csv\",index_col = 'id')\n",
    "sample = pd.read_csv(r\"C:\\Users\\NDO00\\OneDrive\\デスクトップ\\MI\\mi_book\\e-commerce\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2fdff-13d7-4ff3-b0be-0f0fe07e1ce5",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cc3fd73-21c6-4025-b4a3-ee0e9d06fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['target'].copy()\n",
    "#feature_8を削除\n",
    "X_train = train.copy().drop(['target',\"feature_8\"], axis = 1)\n",
    "\n",
    "X_test = test.copy().drop([\"feature_8\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7bbc0c8-05fc-447f-b782-4a3c748e1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(n_estimators = 2000, learning_rate = 0.02,\n",
    "                            random_state = 42, num_class = 4, metric = 'multi_logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8d5aa-4583-44e0-8aba-415650ee9d7d",
   "metadata": {},
   "source": [
    "### ハイパーパラメーター探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37b2ac3d-a11b-48b5-9fd1-189a2d7c5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存したパラメータを読み込むための関数\n",
    "def pickle_load(path):\n",
    "    with open(path,mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9e07635-4382-47d0-97ee-547b8d56c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.46217573119119065, 'max_depth': 14, 'min_child_samples': 70, 'min_child_weight': 0, 'num_leaves': 7, 'reg_alpha': 0.5268214249542319, 'reg_lambda': 0.7393115077693782, 'subsample': 0.6397130890285847}\n"
     ]
    }
   ],
   "source": [
    "#part1で得た特徴量49個モデルのハイパーパラメータ読み込み\n",
    "best_params_full=pickle_load(\"best_params_full.text.\")\n",
    "print(best_params_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f525ff5-c22a-4875-8366-1e961af2af1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.46217573119119065, learning_rate=0.02,\n",
       "               max_depth=14, metric='multi_logloss', min_child_samples=70,\n",
       "               min_child_weight=0, n_estimators=2000, num_class=4, num_leaves=7,\n",
       "               random_state=42, reg_alpha=0.5268214249542319,\n",
       "               reg_lambda=0.7393115077693782, subsample=0.6397130890285847)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#チューニング後のハイパーパラメーターを適用したモデルを出す\n",
    "lgbm_tuned = lgbm_model\n",
    "lgbm_tuned = lgbm_tuned.set_params(**best_params_full)\n",
    "lgbm_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fc06583-200c-4fa1-8f14-81e0382bfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction (X_train, Y_train, model, X_test):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "    y_pred = np.zeros((50000,4))\n",
    "    train_oof = np.zeros((100000,4))\n",
    "    imp=pd.DataFrame()\n",
    "    n=0\n",
    "    \n",
    "    for idx in kfold.split(X=X_train, y=Y_train):\n",
    "        train_idx, val_idx = idx[0], idx[1]\n",
    "        xtrain = X_train.iloc[train_idx]\n",
    "        ytrain = Y_train.iloc[train_idx]\n",
    "        xval = X_train.iloc[val_idx]\n",
    "        yval = Y_train.iloc[val_idx]\n",
    "        \n",
    "        n+=1\n",
    "               \n",
    "        # fit model for current fold\n",
    "        model.fit(xtrain, ytrain, \n",
    "            early_stopping_rounds = 100, eval_set = [(xval,yval)], verbose = False)\n",
    "\n",
    "        #testデータについて予測値を出す　(n_splits個の各モデルについて推論を行うので平均をとる)\n",
    "        y_pred += model.predict_proba(X_test)/kfold.n_splits\n",
    "        print(y_pred)\n",
    "               \n",
    "        val_pred = model.predict_proba(xval)\n",
    "        # getting out-of-fold predictions on training set\n",
    "        train_oof[val_idx] = val_pred\n",
    "        \n",
    "        # imp\n",
    "        _imp = pd.DataFrame({\"col\":X_train.columns, \"imp\":model.feature_importances_, \"nfold\":n})\n",
    "        imp = pd.concat([imp, _imp])\n",
    "        \n",
    "        # calculate and append logloss\n",
    "        fold_logloss = metrics.log_loss(yval,val_pred)\n",
    "        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n",
    "    \n",
    "    #各foldの重要度の平均と標準偏差を算出し、まとめる。\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "    \n",
    "    #テストデータの予測確率、trainデータの予測確率,説明変数の重要度を返す。\n",
    "    return y_pred, train_oof, imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e5517-8e70-474d-90c0-a7aca4abc66e",
   "metadata": {},
   "source": [
    "part1で得た特徴量49個モデルの特徴量重要度の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55933622-1f56-443e-8f2b-420e91db7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.read_csv('imp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a6776-5477-4783-aa57-bc406af4873c",
   "metadata": {},
   "source": [
    "## 特徴量選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "855fcddb-d8fb-4453-b9e8-ba7de1a433dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_14',\n",
       " 'feature_38',\n",
       " 'feature_34',\n",
       " 'feature_31',\n",
       " 'feature_28',\n",
       " 'feature_15',\n",
       " 'feature_9',\n",
       " 'feature_19',\n",
       " 'feature_6',\n",
       " 'feature_17',\n",
       " 'feature_48',\n",
       " 'feature_43',\n",
       " 'feature_7',\n",
       " 'feature_35',\n",
       " 'feature_12',\n",
       " 'feature_18',\n",
       " 'feature_16',\n",
       " 'feature_37',\n",
       " 'feature_5',\n",
       " 'feature_33',\n",
       " 'feature_41',\n",
       " 'feature_25',\n",
       " 'feature_42',\n",
       " 'feature_24',\n",
       " 'feature_11',\n",
       " 'feature_46',\n",
       " 'feature_21',\n",
       " 'feature_39',\n",
       " 'feature_1',\n",
       " 'feature_23',\n",
       " 'feature_45',\n",
       " 'feature_40',\n",
       " 'feature_10',\n",
       " 'feature_26',\n",
       " 'feature_49',\n",
       " 'feature_0',\n",
       " 'feature_32',\n",
       " 'feature_30',\n",
       " 'feature_47',\n",
       " 'feature_4',\n",
       " 'feature_27',\n",
       " 'feature_3',\n",
       " 'feature_20',\n",
       " 'feature_22',\n",
       " 'feature_29',\n",
       " 'feature_2',\n",
       " 'feature_44',\n",
       " 'feature_13',\n",
       " 'feature_36']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特徴量がキーと重要度がバリューの辞書を生成\n",
    "f_imp=dict(zip(imp[\"col\"],imp[\"imp\"]))\n",
    "#特徴量の大きさで降順にソート\n",
    "f_imp = sorted(f_imp.items(), key=lambda x:x[1],reverse=True)\n",
    "f_imp = dict((x, y) for x, y in f_imp)\n",
    "#キーのみをリストとして取得\n",
    "feats=list(f_imp.keys())\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca592cc-dfaf-458e-8f62-637df4062913",
   "metadata": {},
   "source": [
    "### 特徴量を抽出する個数を入れると、使った特徴量の個数と誤差関数が返ってくる関数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ad6fcc2-020a-4a66-b614-169727d0f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_select(n,model):\n",
    "    #上からn個目までの特徴量を抽出\n",
    "    feats_n=feats[:n]\n",
    "    X_train_n = train[feats_n]\n",
    "    Y_train = train['target'].copy()\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "\n",
    "    \n",
    "    loss=[]\n",
    "    \n",
    "    for idx in kfold.split(X=X_train_n, y=Y_train):\n",
    "        train_idx, val_idx = idx[0], idx[1]\n",
    "        xtrain = X_train_n.iloc[train_idx]\n",
    "        ytrain = Y_train.iloc[train_idx]\n",
    "        xval = X_train_n.iloc[val_idx]\n",
    "        yval = Y_train.iloc[val_idx]\n",
    "        \n",
    "\n",
    "               \n",
    "        # fit model for current fold\n",
    "        model.fit(xtrain, ytrain, \n",
    "            early_stopping_rounds = 100, eval_set = [(xval,yval)], verbose = False)\n",
    "\n",
    "               \n",
    "        val_pred = model.predict_proba(xval)\n",
    "\n",
    "        \n",
    "        # calculate and append logloss\n",
    "        fold_logloss = metrics.log_loss(yval,val_pred)\n",
    "        loss.append(fold_logloss)\n",
    "    \n",
    "    #特徴量の個数nと、各foldの誤差の平均を返す\n",
    "    return n, np.mean(loss)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a67cef-0d9c-40f8-986d-b7f5fa100ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1.1167004557532132}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特徴量を上から２個使った場合を例示する。\n",
    "score={}\n",
    "score[feat_select(2,lgbm_tuned)[0]]=feat_select(2,lgbm_tuned)[1]\n",
    "#特徴量の個数と、誤差の対応した辞書\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0105c3f-97bb-4ad1-8c31-cb90e6f03abc",
   "metadata": {},
   "source": [
    "## 何通りか特徴量を選出し、比較する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b689cf36-1d58-4795-9ac4-3e08ada6d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使う特徴量の個数を入れるリスト\n",
    "featlist=[5,10,15,20,25,30,35,40,45]\n",
    "#特徴量と誤差の対応した辞書\n",
    "score={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9401a21-e191-463b-b32e-56decc71a5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 1.1131235893752318,\n",
       " 10: 1.1093661487758655,\n",
       " 15: 1.1073977928570933,\n",
       " 20: 1.1042456268641383,\n",
       " 25: 1.1018667963486393,\n",
       " 30: 1.1002914944692863,\n",
       " 35: 1.098988494285249,\n",
       " 40: 1.0965836724971503,\n",
       " 45: 1.0949763832346258}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in featlist:\n",
    "    score[feat_select(i,lgbm_tuned)[0]]=feat_select(i,lgbm_tuned)[1]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d4d63-2a19-48e5-af4e-ce4fdb33ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('score.text', 'wb') as g:\n",
    "    pickle.dump(score,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5da620-22e4-48ed-a716-f698db82311c",
   "metadata": {},
   "source": [
    "## scoreの中身を見て、誤差が最も小さくなった特徴量の数mを選び、ハイパーパラメーター調整した後にさらに訓練し、予測誤差を下げる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb38ab6-9743-4d4e-9a19-a8863b440340",
   "metadata": {},
   "source": [
    "誤差が最小になる特徴量数mが分かった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cc984ae-88df-470c-aecd-0aea7beef8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_14', 'feature_38', 'feature_34', 'feature_31', 'feature_28', 'feature_15', 'feature_9', 'feature_19', 'feature_6', 'feature_17', 'feature_48', 'feature_43', 'feature_7', 'feature_35', 'feature_12', 'feature_18', 'feature_16', 'feature_37', 'feature_5', 'feature_33', 'feature_41', 'feature_25', 'feature_42', 'feature_24', 'feature_11', 'feature_46', 'feature_21', 'feature_39', 'feature_1', 'feature_23', 'feature_45', 'feature_40', 'feature_10', 'feature_26', 'feature_49', 'feature_0', 'feature_32', 'feature_30', 'feature_47', 'feature_4', 'feature_27', 'feature_3', 'feature_20', 'feature_22', 'feature_29', 'feature_2', 'feature_44', 'feature_13', 'feature_36']\n"
     ]
    }
   ],
   "source": [
    "#一行下に誤差が最も小さくなる特徴量数mを入れる\n",
    "feats_m=feats[:49]\n",
    "print(feats_m)\n",
    "\n",
    "with open('feats_m.txt', 'wb') as g:\n",
    "    pickle.dump(feats_m,g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30d2f3d0-eeef-4072-bb35-e6bbbda1fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m = train[feats_m]\n",
    "X_test_m = test[feats_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8238a65e-212f-4066-9670-c993fc0bb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量をm個使った場合のハイパーパラメーター探索\n",
    "def objective_m(params):\n",
    "\n",
    "    \n",
    "    clf_search = LGBMClassifier(n_estimators = 2000, learning_rate = 0.02, random_state = 42, num_class = 4, metric = 'multi_logloss', verbosity = -1)\n",
    "    clf_search.set_params(**params)\n",
    "   \n",
    "    search_cvpred = cv_function(X_train_m, Y_train, clf_search, splits = 5)  \n",
    "    score =metrics.log_loss(Y_train, search_cvpred)\n",
    "    print(\"Logloss: {0:0.6f}\".format(score)) \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1e8731d-7bd4-4622-9351-012c893d3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習データの分割や、損失などを計算する関数\n",
    "def cv_function (X_train, Y_train, model, splits = 10):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = splits)\n",
    "    logloss = []\n",
    "   \n",
    "    cv_pred = np.zeros((100000,4))\n",
    "    \n",
    "    for idx in kfold.split(X=X_train, y=Y_train):\n",
    "        train_idx, test_idx = idx[0], idx[1]\n",
    "        xtrain = X_train.iloc[train_idx]\n",
    "        ytrain = Y_train.iloc[train_idx]\n",
    "        xtest = X_train.iloc[test_idx]\n",
    "        ytest = Y_train.iloc[test_idx]\n",
    "        \n",
    "        # fit model for current fold\n",
    "        model.fit(xtrain, ytrain, \n",
    "            early_stopping_rounds = 100, eval_set = [(xtest,ytest)], verbose = False)\n",
    "\n",
    "        #create predictions\n",
    "        preds = model.predict_proba(xtest)\n",
    "        cv_pred[test_idx] = preds\n",
    "                              \n",
    "        # calculate and append accuracy\n",
    "        fold_logloss = metrics.log_loss(ytest,preds)\n",
    "        print(\"LogLoss: {0:0.5f}\". format(fold_logloss))\n",
    "        logloss.append(fold_logloss)\n",
    "        \n",
    "    print (np.mean(logloss))\n",
    "    #実行すると損失関数を示す\n",
    "    return cv_pred\n",
    "    #関数の戻り値は訓練データの予測ラベルをかえす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "927f6390-c531-4fb5-a92e-42e46a6873ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ハイパーパラメーターは基本的に一様分布からサンプリングする。\n",
    "#uniform(low,high)は[a,b]間の一様分布からサンプリングする。\n",
    "#quniform(low,high,q)はround(uniform(low, high) / q) * qを返す。\n",
    "params_lgbm_m = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 25, 1)),\n",
    "    \"subsample\": hp.uniform(\"subsample\",0.4,1),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\",0.4,1),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 0.1, 1.0, 0.1)),    \n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 20, 100, 5)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 7, 256, 1)),\n",
    "    \"reg_alpha\": hp.uniform('reg_alpha', 0.0, 1),\n",
    "    \"reg_lambda\": hp.uniform('reg_lambda', 0.0, 1)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b1fd71f-05da-44b9-bdbf-ea1397ef26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: 1.10550                                                                                                       \n",
      "LogLoss: 1.10721                                                                                                       \n",
      "LogLoss: 1.10335                                                                                                       \n",
      "LogLoss: 1.10477                                                                                                       \n",
      "LogLoss: 1.10244                                                                                                       \n",
      "1.1046551560895632                                                                                                     \n",
      "Logloss: 1.104655                                                                                                      \n",
      "LogLoss: 1.10532                                                                                                       \n",
      "LogLoss: 1.10671                                                                                                       \n",
      "LogLoss: 1.10312                                                                                                       \n",
      "LogLoss: 1.10480                                                                                                       \n",
      "LogLoss: 1.10233                                                                                                       \n",
      "1.1044557670269026                                                                                                     \n",
      "Logloss: 1.104456                                                                                                      \n",
      "LogLoss: 1.10411                                                                                                       \n",
      "LogLoss: 1.10534                                                                                                       \n",
      "LogLoss: 1.10129                                                                                                       \n",
      "LogLoss: 1.10379                                                                                                       \n",
      "LogLoss: 1.10172                                                                                                       \n",
      "1.103252652448393                                                                                                      \n",
      "Logloss: 1.103253                                                                                                      \n",
      "LogLoss: 1.10655                                                                                                       \n",
      "LogLoss: 1.10816                                                                                                       \n",
      "LogLoss: 1.10428                                                                                                       \n",
      "LogLoss: 1.10613                                                                                                       \n",
      "LogLoss: 1.10411                                                                                                       \n",
      "1.1058448175524194                                                                                                     \n",
      "Logloss: 1.105845                                                                                                      \n",
      "LogLoss: 1.10382                                                                                                       \n",
      "LogLoss: 1.10503                                                                                                       \n",
      "LogLoss: 1.10087                                                                                                       \n",
      "LogLoss: 1.10323                                                                                                       \n",
      "LogLoss: 1.10101                                                                                                       \n",
      "1.102793614353717                                                                                                      \n",
      "Logloss: 1.102794                                                                                                      \n",
      "LogLoss: 1.10426                                                                                                       \n",
      "LogLoss: 1.10577                                                                                                       \n",
      "LogLoss: 1.10203                                                                                                       \n",
      "LogLoss: 1.10367                                                                                                       \n",
      "LogLoss: 1.10146                                                                                                       \n",
      "1.1034389246132104                                                                                                     \n",
      "Logloss: 1.103439                                                                                                      \n",
      "LogLoss: 1.10373                                                                                                       \n",
      "LogLoss: 1.10496                                                                                                       \n",
      "LogLoss: 1.10068                                                                                                       \n",
      "LogLoss: 1.10347                                                                                                       \n",
      "LogLoss: 1.10096                                                                                                       \n",
      "1.1027612278280343                                                                                                     \n",
      "Logloss: 1.102761                                                                                                      \n",
      "LogLoss: 1.10528                                                                                                       \n",
      "LogLoss: 1.10687                                                                                                       \n",
      "LogLoss: 1.10278                                                                                                       \n",
      "LogLoss: 1.10462                                                                                                       \n",
      "LogLoss: 1.10241                                                                                                       \n",
      "1.1043940185202987                                                                                                     \n",
      "Logloss: 1.104394                                                                                                      \n",
      "LogLoss: 1.10585                                                                                                       \n",
      "LogLoss: 1.10775                                                                                                       \n",
      "LogLoss: 1.10374                                                                                                       \n",
      "LogLoss: 1.10501                                                                                                       \n",
      "LogLoss: 1.10339                                                                                                       \n",
      "1.1051491035707248                                                                                                     \n",
      "Logloss: 1.105149                                                                                                      \n",
      "LogLoss: 1.10447                                                                                                       \n",
      "LogLoss: 1.10595                                                                                                       \n",
      "LogLoss: 1.10299                                                                                                       \n",
      "LogLoss: 1.10397                                                                                                       \n",
      "LogLoss: 1.10261                                                                                                       \n",
      "1.103999011078864                                                                                                      \n",
      "Logloss: 1.103999                                                                                                      \n",
      "LogLoss: 1.10470                                                                                                       \n",
      "LogLoss: 1.10563                                                                                                       \n",
      "LogLoss: 1.10198                                                                                                       \n",
      "LogLoss: 1.10439                                                                                                       \n",
      "LogLoss: 1.10206                                                                                                       \n",
      "1.1037535536763465                                                                                                     \n",
      "Logloss: 1.103754                                                                                                      \n",
      "LogLoss: 1.10627                                                                                                       \n",
      "LogLoss: 1.10746                                                                                                       \n",
      "LogLoss: 1.10309                                                                                                       \n",
      "LogLoss: 1.10479                                                                                                       \n",
      "LogLoss: 1.10286                                                                                                       \n",
      "1.1048938764457723                                                                                                     \n",
      "Logloss: 1.104894                                                                                                      \n",
      "LogLoss: 1.10415                                                                                                       \n",
      "LogLoss: 1.10574                                                                                                       \n",
      "LogLoss: 1.10234                                                                                                       \n",
      "LogLoss: 1.10391                                                                                                       \n",
      "LogLoss: 1.10242                                                                                                       \n",
      "1.103712157221815                                                                                                      \n",
      "Logloss: 1.103712                                                                                                      \n",
      "LogLoss: 1.10500                                                                                                       \n",
      "LogLoss: 1.10642                                                                                                       \n",
      "LogLoss: 1.10241                                                                                                       \n",
      "LogLoss: 1.10403                                                                                                       \n",
      "LogLoss: 1.10166                                                                                                       \n",
      "1.1039052815103023                                                                                                     \n",
      "Logloss: 1.103905                                                                                                      \n",
      "LogLoss: 1.10414                                                                                                       \n",
      "LogLoss: 1.10540                                                                                                       \n",
      "LogLoss: 1.10095                                                                                                       \n",
      "LogLoss: 1.10349                                                                                                       \n",
      "LogLoss: 1.10131                                                                                                       \n",
      "1.103056911930345                                                                                                      \n",
      "Logloss: 1.103057                                                                                                      \n",
      "LogLoss: 1.10406                                                                                                       \n",
      "LogLoss: 1.10543                                                                                                       \n",
      "LogLoss: 1.10148                                                                                                       \n",
      "LogLoss: 1.10380                                                                                                       \n",
      "LogLoss: 1.10144                                                                                                       \n",
      "1.1032404799855258                                                                                                     \n",
      "Logloss: 1.103240                                                                                                      \n",
      "LogLoss: 1.10477                                                                                                       \n",
      "LogLoss: 1.10621                                                                                                       \n",
      "LogLoss: 1.10208                                                                                                       \n",
      "LogLoss: 1.10447                                                                                                       \n",
      "LogLoss: 1.10188                                                                                                       \n",
      "1.1038818872267404                                                                                                     \n",
      "Logloss: 1.103882                                                                                                      \n",
      "LogLoss: 1.10736                                                                                                       \n",
      "LogLoss: 1.10894                                                                                                       \n",
      "LogLoss: 1.10495                                                                                                       \n",
      "LogLoss: 1.10611                                                                                                       \n",
      "LogLoss: 1.10445                                                                                                       \n",
      "1.1063611322841687                                                                                                     \n",
      "Logloss: 1.106361                                                                                                      \n",
      "LogLoss: 1.10537                                                                                                       \n",
      "LogLoss: 1.10688                                                                                                       \n",
      "LogLoss: 1.10306                                                                                                       \n",
      "LogLoss: 1.10451                                                                                                       \n",
      "LogLoss: 1.10235                                                                                                       \n",
      "1.104433817267195                                                                                                      \n",
      "Logloss: 1.104434                                                                                                      \n",
      "LogLoss: 1.10354                                                                                                       \n",
      "LogLoss: 1.10501                                                                                                       \n",
      "LogLoss: 1.10069                                                                                                       \n",
      "LogLoss: 1.10320                                                                                                       \n",
      "LogLoss: 1.10097                                                                                                       \n",
      "1.1026806229570327                                                                                                     \n",
      "Logloss: 1.102681                                                                                                      \n",
      "LogLoss: 1.10409                                                                                                       \n",
      "LogLoss: 1.10572                                                                                                       \n",
      "LogLoss: 1.10155                                                                                                       \n",
      "LogLoss: 1.10381                                                                                                       \n",
      "LogLoss: 1.10110                                                                                                       \n",
      "1.1032531859980703                                                                                                     \n",
      "Logloss: 1.103253                                                                                                      \n",
      "LogLoss: 1.10443                                                                                                       \n",
      "LogLoss: 1.10588                                                                                                       \n",
      "LogLoss: 1.10176                                                                                                       \n",
      "LogLoss: 1.10395                                                                                                       \n",
      "LogLoss: 1.10188                                                                                                       \n",
      "1.1035805904502412                                                                                                     \n",
      "Logloss: 1.103581                                                                                                      \n",
      "LogLoss: 1.10391                                                                                                       \n",
      "LogLoss: 1.10576                                                                                                       \n",
      "LogLoss: 1.10108                                                                                                       \n",
      "LogLoss: 1.10348                                                                                                       \n",
      "LogLoss: 1.10096                                                                                                       \n",
      "1.1030400216725558                                                                                                     \n",
      "Logloss: 1.103040                                                                                                      \n",
      "LogLoss: 1.10596                                                                                                       \n",
      "LogLoss: 1.10694                                                                                                       \n",
      "LogLoss: 1.10353                                                                                                       \n",
      "LogLoss: 1.10579                                                                                                       \n",
      "LogLoss: 1.10301                                                                                                       \n",
      "1.1050471269620212                                                                                                     \n",
      "Logloss: 1.105047                                                                                                      \n",
      "LogLoss: 1.10349                                                                                                       \n",
      "LogLoss: 1.10482                                                                                                       \n",
      "LogLoss: 1.10029                                                                                                       \n",
      "LogLoss: 1.10274                                                                                                       \n",
      "LogLoss: 1.10075                                                                                                       \n",
      "1.1024183194444572                                                                                                     \n",
      "Logloss: 1.102418                                                                                                      \n",
      "LogLoss: 1.10372                                                                                                       \n",
      "LogLoss: 1.10521                                                                                                       \n",
      "LogLoss: 1.10101                                                                                                       \n",
      "LogLoss: 1.10304                                                                                                       \n",
      "LogLoss: 1.10078                                                                                                       \n",
      "1.1027532293977214                                                                                                     \n",
      "Logloss: 1.102753                                                                                                      \n",
      "LogLoss: 1.10484                                                                                                       \n",
      "LogLoss: 1.10669                                                                                                       \n",
      "LogLoss: 1.10270                                                                                                       \n",
      "LogLoss: 1.10386                                                                                                       \n",
      "LogLoss: 1.10203                                                                                                       \n",
      "1.1040238751551714                                                                                                     \n",
      "Logloss: 1.104024                                                                                                      \n",
      "LogLoss: 1.10366                                                                                                       \n",
      "LogLoss: 1.10553                                                                                                       \n",
      "LogLoss: 1.10155                                                                                                       \n",
      "LogLoss: 1.10324                                                                                                       \n",
      "LogLoss: 1.10120                                                                                                       \n",
      "1.1030378107776766                                                                                                     \n",
      "Logloss: 1.103038                                                                                                      \n",
      "LogLoss: 1.10492                                                                                                       \n",
      "LogLoss: 1.10658                                                                                                       \n",
      "LogLoss: 1.10281                                                                                                       \n",
      "LogLoss: 1.10388                                                                                                       \n",
      "LogLoss: 1.10279                                                                                                       \n",
      "1.1041951342177492                                                                                                     \n",
      "Logloss: 1.104195                                                                                                      \n",
      "LogLoss: 1.10453                                                                                                       \n",
      "LogLoss: 1.10617                                                                                                       \n",
      "LogLoss: 1.10194                                                                                                       \n",
      "LogLoss: 1.10363                                                                                                       \n",
      "LogLoss: 1.10141                                                                                                       \n",
      "1.1035378704555383                                                                                                     \n",
      "Logloss: 1.103538                                                                                                      \n",
      "LogLoss: 1.10507                                                                                                       \n",
      "LogLoss: 1.10678                                                                                                       \n",
      "LogLoss: 1.10273                                                                                                       \n",
      "LogLoss: 1.10430                                                                                                       \n",
      "LogLoss: 1.10206                                                                                                       \n",
      "1.104186653602317                                                                                                      \n",
      "Logloss: 1.104187                                                                                                      \n",
      "LogLoss: 1.10417                                                                                                       \n",
      "LogLoss: 1.10520                                                                                                       \n",
      "LogLoss: 1.10121                                                                                                       \n",
      "LogLoss: 1.10392                                                                                                       \n",
      "LogLoss: 1.10159                                                                                                       \n",
      "1.1032167696824096                                                                                                     \n",
      "Logloss: 1.103217                                                                                                      \n",
      "LogLoss: 1.10354                                                                                                       \n",
      "LogLoss: 1.10481                                                                                                       \n",
      "LogLoss: 1.10037                                                                                                       \n",
      "LogLoss: 1.10310                                                                                                       \n",
      "LogLoss: 1.10088                                                                                                       \n",
      "1.1025412113788344                                                                                                     \n",
      "Logloss: 1.102541                                                                                                      \n",
      "LogLoss: 1.10595                                                                                                       \n",
      "LogLoss: 1.10692                                                                                                       \n",
      "LogLoss: 1.10353                                                                                                       \n",
      "LogLoss: 1.10525                                                                                                       \n",
      "LogLoss: 1.10283                                                                                                       \n",
      "1.104897740124889                                                                                                      \n",
      "Logloss: 1.104898                                                                                                      \n",
      "LogLoss: 1.10622                                                                                                       \n",
      "LogLoss: 1.10730                                                                                                       \n",
      "LogLoss: 1.10394                                                                                                       \n",
      "LogLoss: 1.10443                                                                                                       \n",
      "LogLoss: 1.10325                                                                                                       \n",
      "1.105029088556011                                                                                                      \n",
      "Logloss: 1.105029                                                                                                      \n",
      "LogLoss: 1.10434                                                                                                       \n",
      "LogLoss: 1.10597                                                                                                       \n",
      "LogLoss: 1.10193                                                                                                       \n",
      "LogLoss: 1.10351                                                                                                       \n",
      "LogLoss: 1.10116                                                                                                       \n",
      "1.1033793998800445                                                                                                     \n",
      "Logloss: 1.103379                                                                                                      \n",
      "LogLoss: 1.10394                                                                                                       \n",
      "LogLoss: 1.10498                                                                                                       \n",
      "LogLoss: 1.10054                                                                                                       \n",
      "LogLoss: 1.10332                                                                                                       \n",
      "LogLoss: 1.10124                                                                                                       \n",
      "1.1028026008621472                                                                                                     \n",
      "Logloss: 1.102803                                                                                                      \n",
      "LogLoss: 1.10368                                                                                                       \n",
      "LogLoss: 1.10469                                                                                                       \n",
      "LogLoss: 1.10056                                                                                                       \n",
      "LogLoss: 1.10313                                                                                                       \n",
      "LogLoss: 1.10084                                                                                                       \n",
      "1.102579224727851                                                                                                      \n",
      "Logloss: 1.102579                                                                                                      \n",
      "LogLoss: 1.10627                                                                                                       \n",
      "LogLoss: 1.10750                                                                                                       \n",
      "LogLoss: 1.10376                                                                                                       \n",
      "LogLoss: 1.10539                                                                                                       \n",
      "LogLoss: 1.10347                                                                                                       \n",
      "1.1052778133809944                                                                                                     \n",
      "Logloss: 1.105278                                                                                                      \n",
      "LogLoss: 1.10381                                                                                                       \n",
      "LogLoss: 1.10512                                                                                                       \n",
      "LogLoss: 1.10058                                                                                                       \n",
      "LogLoss: 1.10321                                                                                                       \n",
      "LogLoss: 1.10121                                                                                                       \n",
      "1.1027848093163102                                                                                                     \n",
      "Logloss: 1.102785                                                                                                      \n",
      "LogLoss: 1.10489                                                                                                       \n",
      "LogLoss: 1.10637                                                                                                       \n",
      "LogLoss: 1.10245                                                                                                       \n",
      "LogLoss: 1.10438                                                                                                       \n",
      "LogLoss: 1.10212                                                                                                       \n",
      "1.104041553405708                                                                                                      \n",
      "Logloss: 1.104042                                                                                                      \n",
      "LogLoss: 1.10562                                                                                                       \n",
      "LogLoss: 1.10710                                                                                                       \n",
      "LogLoss: 1.10321                                                                                                       \n",
      "LogLoss: 1.10468                                                                                                       \n",
      "LogLoss: 1.10264                                                                                                       \n",
      "1.1046518758258828                                                                                                     \n",
      "Logloss: 1.104652                                                                                                      \n",
      "LogLoss: 1.10442                                                                                                       \n",
      "LogLoss: 1.10602                                                                                                       \n",
      "LogLoss: 1.10197                                                                                                       \n",
      "LogLoss: 1.10412                                                                                                       \n",
      "LogLoss: 1.10147                                                                                                       \n",
      "1.103597531588235                                                                                                      \n",
      "Logloss: 1.103598                                                                                                      \n",
      "LogLoss: 1.10574                                                                                                       \n",
      "LogLoss: 1.10702                                                                                                       \n",
      "LogLoss: 1.10282                                                                                                       \n",
      "LogLoss: 1.10486                                                                                                       \n",
      "LogLoss: 1.10252                                                                                                       \n",
      "1.1045898362655                                                                                                        \n",
      "Logloss: 1.104590                                                                                                      \n",
      "LogLoss: 1.10396                                                                                                       \n",
      "LogLoss: 1.10501                                                                                                       \n",
      "LogLoss: 1.10051                                                                                                       \n",
      "LogLoss: 1.10340                                                                                                       \n",
      "LogLoss: 1.10135                                                                                                       \n",
      "1.102846832523563                                                                                                      \n",
      "Logloss: 1.102847                                                                                                      \n",
      "LogLoss: 1.10569                                                                                                       \n",
      "LogLoss: 1.10733                                                                                                       \n",
      "LogLoss: 1.10378                                                                                                       \n",
      "LogLoss: 1.10483                                                                                                       \n",
      "LogLoss: 1.10274                                                                                                       \n",
      "1.1048733043336314                                                                                                     \n",
      "Logloss: 1.104873                                                                                                      \n",
      "LogLoss: 1.10447                                                                                                       \n",
      "LogLoss: 1.10592                                                                                                       \n",
      "LogLoss: 1.10175                                                                                                       \n",
      "LogLoss: 1.10437                                                                                                       \n",
      "LogLoss: 1.10217                                                                                                       \n",
      "1.1037358471168706                                                                                                     \n",
      "Logloss: 1.103736                                                                                                      \n",
      "LogLoss: 1.10471                                                                                                       \n",
      "LogLoss: 1.10645                                                                                                       \n",
      "LogLoss: 1.10206                                                                                                       \n",
      "LogLoss: 1.10435                                                                                                       \n",
      "LogLoss: 1.10163                                                                                                       \n",
      "1.1038381730342934                                                                                                     \n",
      "Logloss: 1.103838                                                                                                      \n",
      "LogLoss: 1.10704                                                                                                       \n",
      "LogLoss: 1.10894                                                                                                       \n",
      "LogLoss: 1.10481                                                                                                       \n",
      "LogLoss: 1.10636                                                                                                       \n",
      "LogLoss: 1.10446                                                                                                       \n",
      "1.1063223850784591                                                                                                     \n",
      "Logloss: 1.106322                                                                                                      \n",
      "LogLoss: 1.10455                                                                                                       \n",
      "LogLoss: 1.10629                                                                                                       \n",
      "LogLoss: 1.10235                                                                                                       \n",
      "LogLoss: 1.10391                                                                                                       \n",
      "LogLoss: 1.10184                                                                                                       \n",
      "1.103788000139757                                                                                                      \n",
      "Logloss: 1.103788                                                                                                      \n",
      "100%|█████████████████████████████████████████████████| 50/50 [28:47<00:00, 34.55s/trial, best loss: 1.102418319444457]\n",
      "Best: {'colsample_bytree': 0.647029449963611, 'max_depth': 7.0, 'min_child_samples': 75.0, 'min_child_weight': 0.7000000000000001, 'num_leaves': 8.0, 'reg_alpha': 0.7272793239132271, 'reg_lambda': 0.5369919183467708, 'subsample': 0.7853386927113121}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 1.104655156089563, 'status': 'ok'},\n",
       " {'loss': 1.1044557670269026, 'status': 'ok'},\n",
       " {'loss': 1.103252652448393, 'status': 'ok'},\n",
       " {'loss': 1.1058448175524194, 'status': 'ok'},\n",
       " {'loss': 1.102793614353717, 'status': 'ok'},\n",
       " {'loss': 1.1034389246132104, 'status': 'ok'},\n",
       " {'loss': 1.102761227828034, 'status': 'ok'},\n",
       " {'loss': 1.104394018520299, 'status': 'ok'},\n",
       " {'loss': 1.1051491035707246, 'status': 'ok'},\n",
       " {'loss': 1.1039990110788642, 'status': 'ok'},\n",
       " {'loss': 1.1037535536763465, 'status': 'ok'},\n",
       " {'loss': 1.104893876445772, 'status': 'ok'},\n",
       " {'loss': 1.1037121572218147, 'status': 'ok'},\n",
       " {'loss': 1.1039052815103023, 'status': 'ok'},\n",
       " {'loss': 1.103056911930345, 'status': 'ok'},\n",
       " {'loss': 1.1032404799855255, 'status': 'ok'},\n",
       " {'loss': 1.1038818872267404, 'status': 'ok'},\n",
       " {'loss': 1.1063611322841687, 'status': 'ok'},\n",
       " {'loss': 1.104433817267195, 'status': 'ok'},\n",
       " {'loss': 1.1026806229570325, 'status': 'ok'},\n",
       " {'loss': 1.1032531859980703, 'status': 'ok'},\n",
       " {'loss': 1.1035805904502412, 'status': 'ok'},\n",
       " {'loss': 1.1030400216725558, 'status': 'ok'},\n",
       " {'loss': 1.1050471269620215, 'status': 'ok'},\n",
       " {'loss': 1.102418319444457, 'status': 'ok'},\n",
       " {'loss': 1.1027532293977214, 'status': 'ok'},\n",
       " {'loss': 1.1040238751551714, 'status': 'ok'},\n",
       " {'loss': 1.1030378107776768, 'status': 'ok'},\n",
       " {'loss': 1.1041951342177492, 'status': 'ok'},\n",
       " {'loss': 1.1035378704555383, 'status': 'ok'},\n",
       " {'loss': 1.104186653602317, 'status': 'ok'},\n",
       " {'loss': 1.1032167696824096, 'status': 'ok'},\n",
       " {'loss': 1.1025412113788349, 'status': 'ok'},\n",
       " {'loss': 1.104897740124889, 'status': 'ok'},\n",
       " {'loss': 1.1050290885560112, 'status': 'ok'},\n",
       " {'loss': 1.1033793998800447, 'status': 'ok'},\n",
       " {'loss': 1.1028026008621474, 'status': 'ok'},\n",
       " {'loss': 1.102579224727851, 'status': 'ok'},\n",
       " {'loss': 1.1052778133809944, 'status': 'ok'},\n",
       " {'loss': 1.10278480931631, 'status': 'ok'},\n",
       " {'loss': 1.104041553405708, 'status': 'ok'},\n",
       " {'loss': 1.1046518758258825, 'status': 'ok'},\n",
       " {'loss': 1.103597531588235, 'status': 'ok'},\n",
       " {'loss': 1.1045898362655002, 'status': 'ok'},\n",
       " {'loss': 1.1028468325235627, 'status': 'ok'},\n",
       " {'loss': 1.1048733043336314, 'status': 'ok'},\n",
       " {'loss': 1.1037358471168703, 'status': 'ok'},\n",
       " {'loss': 1.1038381730342934, 'status': 'ok'},\n",
       " {'loss': 1.1063223850784594, 'status': 'ok'},\n",
       " {'loss': 1.1037880001397569, 'status': 'ok'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_m = Trials()\n",
    "\n",
    "best_m = fmin(\n",
    "    fn=objective_m,\n",
    "    space = params_lgbm_m, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=50, \n",
    "    trials=trials_m\n",
    ")\n",
    "#max_evalsで何回探索ループ回すか設定\n",
    "\n",
    "print(\"Best: {}\".format(best_m))\n",
    "trials_m.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adb919d4-b05b-47f5-a411-6658df6666fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.647029449963611, 'max_depth': 7, 'min_child_samples': 75, 'min_child_weight': 0, 'num_leaves': 8, 'reg_alpha': 0.7272793239132271, 'reg_lambda': 0.5369919183467708, 'subsample': 0.7853386927113121}\n"
     ]
    }
   ],
   "source": [
    "best_params_lgbm_m = space_eval(params_lgbm_m, best_m)\n",
    "print(best_params_lgbm_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdf56724-8531-4737-be1e-6827322f7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#チューニングしたハイパーパラメーター保存\n",
    "with open('best_params_lgbm_m.text', 'wb') as g:\n",
    "    pickle.dump(best_params_lgbm_m,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c755986e-f044-4f8b-905a-dbb4aa66dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.647029449963611, 'max_depth': 7, 'min_child_samples': 75, 'min_child_weight': 0, 'num_leaves': 8, 'reg_alpha': 0.7272793239132271, 'reg_lambda': 0.5369919183467708, 'subsample': 0.7853386927113121}\n"
     ]
    }
   ],
   "source": [
    "#読み込んで確認\n",
    "best_params_m_full=pickle_load(\"best_params_lgbm_m.text.\")\n",
    "print(best_params_m_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e47f3e50-bc5f-4d70-b649-c625bec8d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.647029449963611, learning_rate=0.02,\n",
       "               max_depth=7, metric='multi_logloss', min_child_samples=75,\n",
       "               min_child_weight=0, n_estimators=2000, num_class=4, num_leaves=8,\n",
       "               random_state=42, reg_alpha=0.7272793239132271,\n",
       "               reg_lambda=0.5369919183467708, subsample=0.7853386927113121)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#チューニング後のハイパーパラメーターを適用したモデルを出す\n",
    "lgbm_tuned_m = lgbm_model\n",
    "lgbm_tuned_m = lgbm_tuned.set_params(**best_params_m_full)\n",
    "lgbm_tuned_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d102406-dd72-4b83-a3a8-fe73dd6f1be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00881174 0.05721949 0.0200128  0.01395596]\n",
      " [0.00837647 0.07106138 0.01209532 0.00846682]\n",
      " [0.00857529 0.06206013 0.02132353 0.00804105]\n",
      " ...\n",
      " [0.00835147 0.05317384 0.0225215  0.0159532 ]\n",
      " [0.00909024 0.06057075 0.01846704 0.01187197]\n",
      " [0.00861682 0.05341541 0.02066354 0.01730422]]\n",
      "Logloss: 1.10398\n",
      "[[0.0179375  0.11344551 0.04031666 0.02830033]\n",
      " [0.0193706  0.14011185 0.02383516 0.01668239]\n",
      " [0.0179355  0.12228147 0.04318968 0.01659335]\n",
      " ...\n",
      " [0.01692593 0.10415005 0.04575271 0.03317132]\n",
      " [0.01784738 0.12076688 0.0368662  0.02451953]\n",
      " [0.01705273 0.10761693 0.04124314 0.03408719]]\n",
      "Logloss: 1.10261\n",
      "[[0.02651026 0.17035939 0.06070678 0.04242357]\n",
      " [0.0296716  0.20912896 0.03637203 0.02482741]\n",
      " [0.02537788 0.18584584 0.06368457 0.02509171]\n",
      " ...\n",
      " [0.02489693 0.1568785  0.06882312 0.04940146]\n",
      " [0.02656187 0.18067333 0.05464751 0.03811729]\n",
      " [0.0256611  0.160752   0.06188972 0.05169718]]\n",
      "Logloss: 1.10330\n",
      "[[0.0355196  0.22635111 0.08213383 0.05599545]\n",
      " [0.0387788  0.27801422 0.04912099 0.03408599]\n",
      " [0.03389154 0.24759474 0.08415341 0.03436031]\n",
      " ...\n",
      " [0.03345848 0.20987059 0.09151321 0.06515772]\n",
      " [0.03495205 0.24147444 0.07268096 0.05089256]\n",
      " [0.03412508 0.2148833  0.0821186  0.06887301]]\n",
      "Logloss: 1.10484\n",
      "[[0.04382942 0.28374878 0.10315994 0.06926185]\n",
      " [0.04702183 0.34892262 0.06168716 0.0423684 ]\n",
      " [0.04212106 0.31131471 0.10376814 0.04279608]\n",
      " ...\n",
      " [0.04209878 0.26304878 0.11385044 0.081002  ]\n",
      " [0.04340378 0.30199242 0.09060776 0.06399605]\n",
      " [0.04260536 0.26962867 0.10230246 0.08546351]]\n",
      "Logloss: 1.09834\n",
      "[[0.05224485 0.34198995 0.12319515 0.08257006]\n",
      " [0.05550688 0.42055784 0.07381874 0.05011654]\n",
      " [0.05137405 0.37426724 0.12354685 0.05081185]\n",
      " ...\n",
      " [0.05122202 0.31478996 0.13693115 0.09705687]\n",
      " [0.05216678 0.36246425 0.10864605 0.07672292]\n",
      " [0.05158735 0.32337424 0.12265223 0.10238618]]\n",
      "Logloss: 1.10231\n",
      "[[0.06141204 0.39790054 0.14457004 0.09611739]\n",
      " [0.06505171 0.49177913 0.08474781 0.05842135]\n",
      " [0.05956887 0.4362157  0.14437973 0.0598357 ]\n",
      " ...\n",
      " [0.05936865 0.36724599 0.16030271 0.11308266]\n",
      " [0.06069858 0.42432321 0.12599774 0.08898047]\n",
      " [0.06057545 0.37619611 0.14373313 0.11949531]]\n",
      "Logloss: 1.09938\n",
      "[[0.06999307 0.4549412  0.16579784 0.10926789]\n",
      " [0.07368114 0.56250597 0.09714205 0.06667084]\n",
      " [0.06730771 0.50261749 0.16219706 0.06787774]\n",
      " ...\n",
      " [0.06814334 0.41887735 0.18337769 0.12960162]\n",
      " [0.06926944 0.48383682 0.14509607 0.10179767]\n",
      " [0.06906715 0.42913444 0.16388419 0.13791422]]\n",
      "Logloss: 1.10644\n",
      "[[0.0790609  0.51237142 0.18611887 0.1224488 ]\n",
      " [0.08598636 0.63126264 0.1090331  0.0737179 ]\n",
      " [0.07559323 0.56703213 0.18223316 0.07514147]\n",
      " ...\n",
      " [0.07667148 0.47081283 0.20667438 0.14584131]\n",
      " [0.07814484 0.54472335 0.16300361 0.11412821]\n",
      " [0.07773842 0.48349867 0.18419825 0.15456467]]\n",
      "Logloss: 1.09971\n",
      "[[0.08836473 0.56971139 0.20597891 0.13594496]\n",
      " [0.09446533 0.70195307 0.12187766 0.08170394]\n",
      " [0.08376933 0.62867713 0.20311077 0.08444277]\n",
      " ...\n",
      " [0.08476195 0.52309866 0.23034256 0.16179684]\n",
      " [0.08747825 0.60527931 0.18135791 0.12588453]\n",
      " [0.08655446 0.53613783 0.20517967 0.17212804]]\n",
      "Logloss: 1.10075\n"
     ]
    }
   ],
   "source": [
    "##テストデータの予測確率、trainデータの予測確率,説明変数の重要度を返す。\n",
    "lgbm_pred_m, train_oof_m, imp_m = prediction (X_train_m, Y_train, lgbm_tuned_m, X_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19a58d25-f50e-473c-952b-5b835643a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの保存\n",
    "with open('lgbm_tuned_m.pickle', 'wb') as g:\n",
    "    pickle.dump(lgbm_tuned_m,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76945f42-4d6f-4cf5-b8a1-f43d36c27192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(colsample_bytree=0.647029449963611, learning_rate=0.02,\n",
      "               max_depth=7, metric='multi_logloss', min_child_samples=75,\n",
      "               min_child_weight=0, n_estimators=2000, num_class=4, num_leaves=8,\n",
      "               random_state=42, reg_alpha=0.7272793239132271,\n",
      "               reg_lambda=0.5369919183467708, subsample=0.7853386927113121)\n"
     ]
    }
   ],
   "source": [
    "with open('lgbm_tuned_m.pickle', 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9662c7c5-ef95-4cd4-9556-e10df289dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_38</td>\n",
       "      <td>1712.6</td>\n",
       "      <td>287.647238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_14</td>\n",
       "      <td>1618.7</td>\n",
       "      <td>247.473029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_31</td>\n",
       "      <td>1366.5</td>\n",
       "      <td>200.409165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_34</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>180.310843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_28</td>\n",
       "      <td>1155.6</td>\n",
       "      <td>194.353744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_15</td>\n",
       "      <td>1073.6</td>\n",
       "      <td>179.038295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_19</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>199.383048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>986.4</td>\n",
       "      <td>143.078223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_48</td>\n",
       "      <td>981.7</td>\n",
       "      <td>204.123628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_6</td>\n",
       "      <td>947.7</td>\n",
       "      <td>116.466543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_35</td>\n",
       "      <td>940.3</td>\n",
       "      <td>128.999612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_7</td>\n",
       "      <td>909.5</td>\n",
       "      <td>163.400156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_43</td>\n",
       "      <td>886.9</td>\n",
       "      <td>154.174829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_17</td>\n",
       "      <td>880.3</td>\n",
       "      <td>150.790546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_12</td>\n",
       "      <td>859.4</td>\n",
       "      <td>80.537362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_42</td>\n",
       "      <td>857.6</td>\n",
       "      <td>104.581919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_41</td>\n",
       "      <td>840.6</td>\n",
       "      <td>153.284195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_37</td>\n",
       "      <td>829.1</td>\n",
       "      <td>100.515836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_16</td>\n",
       "      <td>799.4</td>\n",
       "      <td>91.071645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_33</td>\n",
       "      <td>799.3</td>\n",
       "      <td>101.621356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_25</td>\n",
       "      <td>794.2</td>\n",
       "      <td>81.498194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>789.1</td>\n",
       "      <td>68.775722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_24</td>\n",
       "      <td>785.3</td>\n",
       "      <td>123.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>767.0</td>\n",
       "      <td>99.428366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_18</td>\n",
       "      <td>759.2</td>\n",
       "      <td>120.134924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col     imp     imp_std\n",
       "16  feature_38  1712.6  287.647238\n",
       "2   feature_14  1618.7  247.473029\n",
       "11  feature_31  1366.5  200.409165\n",
       "13  feature_34  1309.0  180.310843\n",
       "10  feature_28  1155.6  194.353744\n",
       "3   feature_15  1073.6  179.038295\n",
       "7   feature_19  1024.6  199.383048\n",
       "24   feature_9   986.4  143.078223\n",
       "20  feature_48   981.7  204.123628\n",
       "22   feature_6   947.7  116.466543\n",
       "14  feature_35   940.3  128.999612\n",
       "23   feature_7   909.5  163.400156\n",
       "19  feature_43   886.9  154.174829\n",
       "5   feature_17   880.3  150.790546\n",
       "1   feature_12   859.4   80.537362\n",
       "18  feature_42   857.6  104.581919\n",
       "17  feature_41   840.6  153.284195\n",
       "15  feature_37   829.1  100.515836\n",
       "4   feature_16   799.4   91.071645\n",
       "12  feature_33   799.3  101.621356\n",
       "9   feature_25   794.2   81.498194\n",
       "21   feature_5   789.1   68.775722\n",
       "8   feature_24   785.3  123.912200\n",
       "0   feature_11   767.0   99.428366\n",
       "6   feature_18   759.2  120.134924"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重要度を降順に出す。\n",
    "imp_m.sort_values(\"imp\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d89c3617-ac1c-4f06-9369-4c580548ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_m.to_csv('imp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c828c097-aa83-4062-9e48-012e5695ac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.569711</td>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.135945</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094465</td>\n",
       "      <td>0.701953</td>\n",
       "      <td>0.121878</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083769</td>\n",
       "      <td>0.628677</td>\n",
       "      <td>0.203111</td>\n",
       "      <td>0.084443</td>\n",
       "      <td>100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078448</td>\n",
       "      <td>0.535690</td>\n",
       "      <td>0.251393</td>\n",
       "      <td>0.134469</td>\n",
       "      <td>100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076079</td>\n",
       "      <td>0.619962</td>\n",
       "      <td>0.193721</td>\n",
       "      <td>0.110238</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.090912</td>\n",
       "      <td>0.672145</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>0.079799</td>\n",
       "      <td>149995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.076899</td>\n",
       "      <td>0.641277</td>\n",
       "      <td>0.154165</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>149996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.084762</td>\n",
       "      <td>0.523099</td>\n",
       "      <td>0.230343</td>\n",
       "      <td>0.161797</td>\n",
       "      <td>149997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.087478</td>\n",
       "      <td>0.605279</td>\n",
       "      <td>0.181358</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>149998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.086554</td>\n",
       "      <td>0.536138</td>\n",
       "      <td>0.205180</td>\n",
       "      <td>0.172128</td>\n",
       "      <td>149999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class_1   Class_2   Class_3   Class_4      id\n",
       "0      0.088365  0.569711  0.205979  0.135945  100000\n",
       "1      0.094465  0.701953  0.121878  0.081704  100001\n",
       "2      0.083769  0.628677  0.203111  0.084443  100002\n",
       "3      0.078448  0.535690  0.251393  0.134469  100003\n",
       "4      0.076079  0.619962  0.193721  0.110238  100004\n",
       "...         ...       ...       ...       ...     ...\n",
       "49995  0.090912  0.672145  0.157144  0.079799  149995\n",
       "49996  0.076899  0.641277  0.154165  0.127659  149996\n",
       "49997  0.084762  0.523099  0.230343  0.161797  149997\n",
       "49998  0.087478  0.605279  0.181358  0.125885  149998\n",
       "49999  0.086554  0.536138  0.205180  0.172128  149999\n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kaggleに提出するcsvファイルを作成\n",
    "pred_test_m = pd.DataFrame(lgbm_pred_m, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\n",
    "output_m = pred_test_m\n",
    "output_m['id'] = X_test.index\n",
    "output_m.to_csv('submission_m.csv', index=False)\n",
    "\n",
    "output_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdbb57-f550-4dfe-9d87-78b827dfbaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
